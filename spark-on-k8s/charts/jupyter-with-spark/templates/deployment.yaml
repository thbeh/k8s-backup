apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: {{ template "jupyter-with-spark.fullname" . }}
  labels:
    app: {{ template "jupyter-with-spark.name" . }}
    chart: {{ template "jupyter-with-spark.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ template "jupyter-with-spark.name" . }}
      release: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app: {{ template "jupyter-with-spark.name" . }}
        release: {{ .Release.Name }}
    spec:
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - name: http
              containerPort: {{ .Values.jupyterService.jupyterPort }}
              protocol: TCP
            - name: web-ui
              containerPort: {{ .Values.jupyterService.sparkUIPort }}
              protocol: TCP
          command:
            - "/bin/sh"
            - "-c"
            - >
              jupyter notebook --generate-config;
              size=$(wc -c < /tmp/conf/jupyter/jupyter_notebook_config.py);
              if [ $size -gt 0 ]; then cp /tmp/conf/jupyter/jupyter_notebook_config.py /home/jovyan/.jupyter/jupyter_notebook_config.py; fi;
              cp /tmp/conf/spark/* /opt/spark/conf/;
              mkdir -p /home/jovyan/notebooks;
              prefix=`date +%s%N | cut -b1-13`;
              echo "" >> /opt/spark/conf/spark-defaults.conf;
              echo "spark.master                                   k8s://https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT" >> /opt/spark/conf/spark-defaults.conf;
              echo "spark.kubernetes.driver.pod.name               $HOSTNAME" >> /opt/spark/conf/spark-defaults.conf;
              echo "spark.kubernetes.executor.podNamePrefix        spark-$prefix" >> /opt/spark/conf/spark-defaults.conf;
              echo "spark.kubernetes.authenticate.driver.serviceAccountName {{ .Values.global.serviceAccount | default .Values.serviceAccount }}" >> /opt/spark/conf/spark-defaults.conf;
              echo "spark.ui.port                                  {{ .Values.jupyterService.sparkUIPort }}" >> /opt/spark/conf/spark-defaults.conf;
              echo "spark.kubernetes.namespace                     {{ .Release.Namespace }}" >> /opt/spark/conf/spark-defaults.conf;
            {{- if .Values.sparkEventLog.enableHistoryEvents }}
              echo "spark.eventLog.enabled                         true" >> /opt/spark/conf/spark-defaults.conf;
              echo "spark.eventLog.dir                             {{ .Values.sparkEventLog.eventLogDir }}" >> /opt/spark/conf/spark-defaults.conf;
            {{- end }}
            {{- if or .Values.mountSecrets .Values.global.mountSecrets }}
              echo "spark.kubernetes.driver.secrets.{{ .Release.Name }}-secrets   /etc/secrets" >> /opt/spark/conf/spark-defaults.conf;
            {{- end }}
            {{- if eq .Values.jupyterService.password "" }}
              . /usr/local/bin/start.sh jupyter notebook --NotebookApp.token='' --NotebookApp.port={{ .Values.jupyterService.jupyterPort }};
            {{ else }}
              echo "{ \"NotebookApp\": { \"password\": \"REPLACE_ME\" } }" > ~/.jupyter/jupyter_notebook_config.json;
              printf "import os\nfrom notebook.auth import passwd\nprint(passwd('{{ .Values.jupyterService.password }}'))" > hash.py;
              export HASHED=`python hash.py`;
              rm hash.py;
              sed -i -e "s/REPLACE_ME/${HASHED}/g" ~/.jupyter/jupyter_notebook_config.json;
              . /usr/local/bin/start.sh jupyter notebook --NotebookApp.port={{ .Values.jupyterService.jupyterPort }};
            {{- end }}
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources:
{{ toYaml .Values.resources | indent 12 }}
          volumeMounts:
          - name: data
            mountPath: /data/
          - name: spark-config
            mountPath: /tmp/conf/spark/
          - name: jupyter-config
            mountPath: /tmp/conf/jupyter/
        {{- if or .Values.mountSecrets .Values.global.mountSecrets }}
          - name: secrets-volume
            mountPath: /etc/secrets/
        {{- end }}
    {{- with .Values.nodeSelector }}
      nodeSelector:
{{ toYaml . | indent 8 }}
    {{- end }}
      serviceAccount: {{ .Values.serviceAccount }}
    {{- with .Values.affinity }}
      affinity:
{{ toYaml . | indent 8 }}
    {{- end }}
    {{- with .Values.tolerations }}
      tolerations:
{{ toYaml . | indent 8 }}
    {{- end }}
      volumes:
        - name: data
        {{- if .Values.persistence.enabled }}
          persistentVolumeClaim:
            claimName: {{ .Values.persistence.existingClaim | default (include "jupyter-with-spark.fullname" .) }}
        {{- else }}
          emptyDir: {}
        {{- end }}
        - name: jupyter-config
          configMap:
            name: {{ .Release.Name }}-jupyter-configmap
        - name: spark-config
          configMap:
            name: {{ .Release.Name }}-jp-spark-configmap
        {{- if or .Values.mountSecrets .Values.global.mountSecrets }}
        - name: secrets-volume
          secret:
            secretName: {{ .Release.Name }}-jp-secrets
        {{- end }}